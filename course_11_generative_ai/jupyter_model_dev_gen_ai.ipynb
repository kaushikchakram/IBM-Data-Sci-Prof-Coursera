{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-Coursera/laptop_pricing_dataset_mod1.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import Ridge\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": "def read_csv_to_dataframe(file_path):\n    \"\"\"\n    Reads a CSV file located at the provided file path into a Pandas DataFrame.\n    \n    Args:\n    file_path (str): The path to the CSV file.\n    \n    Returns:\n    pandas.DataFrame: The data read from the CSV file.\n    \"\"\"\n    try:\n        # Reading the CSV file into DataFrame\n        df = pd.read_csv(file_path)\n        return df\n    except FileNotFoundError:\n        print(f\"The file at {file_path} was not found.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    \n    return None\n\n# Example usage:\n# Assuming `file_path` is already defined as the path to your CSV\nfile_path = \"./dataset.csv\"\ndf = read_csv_to_dataframe(file_path)\n\nif df is not None:\n    print(df.head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "   Unnamed: 0 Manufacturer  Category     Screen  GPU  OS  CPU_core  \\\n0           0         Acer         4  IPS Panel    2   1         5   \n1           1         Dell         3    Full HD    1   1         3   \n2           2         Dell         3    Full HD    1   1         7   \n3           3         Dell         4  IPS Panel    2   1         5   \n4           4           HP         4    Full HD    2   1         7   \n\n   Screen_Size_cm  CPU_frequency  RAM_GB  Storage_GB_SSD  Weight_kg  Price  \n0          35.560            1.6       8             256       1.60    978  \n1          39.624            2.0       4             256       2.20    634  \n2          39.624            2.7       8             256       2.20    946  \n3          33.782            1.6       8             128       1.22   1244  \n4          39.624            1.8       8             256       1.91    837  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "# Generate ML Linear Regression Model:\n# Check and display NaN values in the DataFrame\nprint(df.isnull().sum())\n\n# Initialize the imputer to fill NaN values with median\nimputer = SimpleImputer(strategy='median')\n\n# Fit the imputer on the 'Weight_kg' column and transform the dataframe\ndf[['Weight_kg']] = imputer.fit_transform(df[['Weight_kg']])\n\n# Select the source (predictor) and target (response) variables\nX = df[['Weight_kg']]  # Using 'Weight_kg' as the predictor\ny = df['Price']       # Using 'Price' as the response\n\n# Splitting the data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate and display the Mean Squared Error (MSE) and R-squared (R²)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R²): {r2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Unnamed: 0        0\nManufacturer      0\nCategory          0\nScreen            0\nGPU               0\nOS                0\nCPU_core          0\nScreen_Size_cm    4\nCPU_frequency     0\nRAM_GB            0\nStorage_GB_SSD    0\nWeight_kg         5\nPrice             0\ndtype: int64\nMean Squared Error (MSE): 269971.1773376724\nR-squared (R²): -0.17142413752152041\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "# Generate ML Linear Regression Model:\n# Select source (predictor) and target (response) variables\nX = df[['CPU_frequency']]  # Using 'CPU_frequency' as the predictor\ny = df['Price']             # Using 'Price' as the response\n\n# Splitting the data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate and display the Mean Squared Error (MSE) and R-squared (R²)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R²): {r2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error (MSE): 239035.99429436037\nR-squared (R²): -0.03719417833496452\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "# Generate ML Linear Regression Model with multiple features for X:\n# Select source (predictor) variables and target (response) variable\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']  # Using 'Price' as the response variable\n\n# Convert categorical variables into numerical format using one-hot encoding\nX = pd.get_dummies(X, drop_first=True)\n\n# Splitting the data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Calculate and display the Mean Squared Error (MSE) and R-squared (R²)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R²): {r2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error (MSE): 168575.62043820196\nR-squared (R²): 0.26853839463024776\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "### The model performance is \"better\" when we use multiple features.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Generate ML Polynomial Regression Model:\n# Select source (predictor) and target (response) variables\nX = df[['CPU_frequency']]\ny = df['Price']\n\n# Splitting the data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define polynomial feature degrees\ndegrees = [2, 3, 5]\n\n# Initialize lists to store results\nmse_scores = []\nr2_scores = []\n\n# Train and evaluate polynomial regression models for different degrees\nfor degree in degrees:\n    # Generate polynomial and affine features\n    poly = PolynomialFeatures(degree=degree, include_bias=False)\n    X_poly_train = poly.fit_transform(X_train)\n    X_poly_test = poly.transform(X_test)\n    \n    # Initialize and train Linear Regression model\n    model = LinearRegression()\n    model.fit(X_poly_train, y_train)\n\n    # Predict on the test set\n    y_pred = model.predict(X_poly_test)\n\n    # Calculate and store MSE and R²\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    mse_scores.append(mse)\n    r2_scores.append(r2)\n\n    print(f\"Polynomial Degree: {degree}\")\n    print(f\"Mean Squared Error (MSE): {mse}\")\n    print(f\"R-squared (R²): {r2}\")\n    print(\"\\n\")\n\n# Compare performance\nfor i in range(len(degrees)):\n    print(f\"Model Degree {degrees[i]}: MSE = {mse_scores[i]}, R² = {r2_scores[i]}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Polynomial Degree: 2\nMean Squared Error (MSE): 196263.5614577202\nR-squared (R²): 0.14839844951318837\n\n\nPolynomial Degree: 3\nMean Squared Error (MSE): 205918.03020812548\nR-squared (R²): 0.10650702302573634\n\n\nPolynomial Degree: 5\nMean Squared Error (MSE): 207335.70360838601\nR-squared (R²): 0.1003556373238833\n\n\nModel Degree 2: MSE = 196263.5614577202, R² = 0.14839844951318837\nModel Degree 3: MSE = 205918.03020812548, R² = 0.10650702302573634\nModel Degree 5: MSE = 207335.70360838601, R² = 0.1003556373238833\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "# Generate ML Linear Regression Model with pipeline:\n# Select source (predictor) variables and target (response) variable\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Splitting the data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Preprocessing steps\nnumeric_features = ['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core']\nnumeric_transformer = StandardScaler()\n\ncategorical_features = ['OS', 'GPU', 'Category']\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore')\n\n# Bundle preprocessing steps and estimator into a single pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])\n\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', LinearRegression())\n])\n\n# Train the model using the pipeline\npipeline.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = pipeline.predict(X_test)\n\n# Calculate and display the Mean Squared Error (MSE) and R-squared (R²)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R²): {r2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Squared Error (MSE): 137926.64583333334\nR-squared (R²): 0.40152647504862826\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "**Once the pipline is created with standardization it perfoms better than what it does previously.**",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Generate ML Ridge Regression Model with GridSearchCV:\n# Select source (predictor) variables and target (response) variable\nX = df[['CPU_frequency', 'RAM_GB', 'Storage_GB_SSD', 'CPU_core', 'OS', 'GPU', 'Category']]\ny = df['Price']\n\n# Splitting the data into training and testing sets (80-20 split)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define polynomial feature generator\npoly = PolynomialFeatures(degree=2, include_bias=False)\nX_train_transformed = poly.fit_transform(X_train)\nX_test_transformed = poly.transform(X_test)\n\n# Define the Ridge Regression model and grid for hyperparameter 'alpha'\nridge = Ridge()\nparam_grid = {'ridge__alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n\n# Setup GridSearchCV\ngrid_search = GridSearchCV(Pipeline(steps=[('poly', poly), ('ridge', ridge)]),\\\n                           param_grid, cv=4, scoring='neg_mean_squared_error')\n\n# Fit the model\ngrid_search.fit(X_train_transformed, y_train)\n\n# Get the best model and parameters\nbest_model = grid_search.best_estimator_\nalpha_best = grid_search.best_params_['ridge__alpha']\nprint(f\"Best Alpha from Grid Search: {alpha_best}\")\n\n# Predict using the best model\ny_pred = best_model.predict(X_test_transformed)\n\n# Calculate and display MSE and R²\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE) with best model: {mse}\")\nprint(f\"R-squared (R²) with best model: {r2}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Best Alpha from Grid Search: 0.0001\nMean Squared Error (MSE) with best model: 2508725.0008351263\nR-squared (R²) with best model: -9.88553618709533\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### My comments:\n----\n#### Practicing with Gen AI:\nIn this script, we are practicing how generative AI prompts work, such that it can generate code according to your needs.\nIn this example, we try to use it for ML Model development from a given dataset to make this process quicker and more efficient. We try to get insights with statistical descriptions, correlative insights, and some plottting usng Gen AI prompts.\n\nThe AI generated code is written based on specific prompts that were given to it by me, based on the instructions specified in the lab:\n\n**Examples of The prompts that were given to the AI (IBM Granite 3.2 8B(Reasoning)):**\n\n**prompt 1:**\n\n```\nWrite a Python code that can perform the following tasks.\nRead the CSV file, located on a given file path, into a pandas data frame, assuming that the first row of the file can be used as the headers for the data.\n```\n\n**prompt 2:** \n```\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable and another as a target variable.\n2. Calculate and display the MSE and R^2 values for the trained model\n```\nThis was produces it with `Weight_kg` as `X` and the target variable `Y` as `Price`.\n\n**prompt 3:**\n```\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses one attribute of a data frame as the source variable 'CPU_frequency' and another as a target variable 'Price'.\n2. Calculate and display the MSE and R^2 values for the trained model\n```\n**prompt 4:**\n```\nWrite a Python code that performs the following tasks.\n1. Develops and trains a linear regression model that uses some attributes of a data frame as the source variables (\"CPU_frequency, RAM_GB, Storage_GB_SSD, CPU_core, OS, GPU and Category\") and one of the attributes as a target variable (\"Price\").\n2. Calculate and display the MSE and R^2 values for the trained model.\n```\n#### The model performance is \"better\" when we use multiple features compared to the previous prompts when we use a single feature for x.\n\n**prompt 5:**\n```\nWrite a Python code that performs the following tasks.\n1. Develops and trains multiple polynomial regression models, with orders 2, 3, and 5, that use one attribute of a data frame as the source variable ('CPU_frequency') and another as a target variable ('Price').\n2. Calculate and display the MSE and R^2 values for the trained models.\n3. Compare the performance of the models.\n```\n#### If we compare the result that we got for prompt 3 and the result for prompt 5:\n**Note: for both prompt 3 and prompt 5 (source variable `CPU_frequency` and target variable `Price`), but for prompt 3 we run a LinearRegression model, whereas for prompt 5 we runa polynomial regression.**\n\n> We find that the polynomial Regression model generated by prompt 5 with degree = 2 is the 'best' model out of the ones we have tested here. \n\n**prompt 6:**\n```\nWrite a Python code that performs the following tasks.\n1. Create a pipeline that performs parameter scaling, Polynomial Feature generation, and Linear regression. Use the set of multiple features as before to create this pipeline. Source variables are: 'CPU_frequency, RAM_GB, Storage_GB_SSD, CPU_core, OS, GPU and Category' and target variable 'Price'.\n2. Calculate and display the MSE and R^2 values for the trained model.\n```\n\n**prompt 7:**\n```\nWrite a Python code that performs the following tasks.\n1. Use polynomial features for some of the attributes of a data frame. Source Variables: CPU_frequency, RAM_GB, Storage_GB_SSD, CPU_core, OS, GPU and Category. Target variable is Price.\n2. Perform Grid search on a ridge regression model for a set of values of hyperparameter alpha and polynomial features as input.Set of values for alpha: 0.0001,0.001,0.01, 0.1, 1, 10\nCross Validation: 4-fold\nPolynomial Feature order: 2\n3. Use cross-validation in the Grid search.\n4. Evaluate the resulting model's MSE and R^2 values.\n```\n#### Overall, It does the job well enough for the example or the tasks required for this lab.\n\n----",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Authors\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright © 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}